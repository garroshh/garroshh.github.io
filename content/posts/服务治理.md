---
weight: 1
title: "服务治理"
date: 2020-05-13T18:29:31+08:00
draft: false

tags: ["Istio", "实验"]
categories: ["Istio"]

lightgallery: true

toc:
  auto: false
---

为了使系统不出现单点故障，服务需要有多个实例增加冗余来提高高可用性，这就需要负载均衡技术；为了请求处理的高效性，又要求有会话保持功能；重试是服务的容错处理机制；故障注入是对系统鲁棒性的测试方法；熔断限流用于保护服务端且提高整个系统的稳定性。Istio 在不侵入代码的情况下，可以提供以上这些流量治理的技术。

# 1. 流量负载均衡

在选择集群中的多个实例之间分配流量时，要考虑用最有效的方式利用资源。可以通过设置 DestinationRule 的 spec.trafficPolicy.loadBalance.simple

字段，来选择合适的负载均衡算法。

## 1.1. ROUND_ROBIN 模式

### 1.1.1. 实验目标

为 advertisement 服务配置 ROUND_ROBIN 算法，期望对 advertisement 服务的请求被平均分配到后端实例。

### 1.1.2. 实验演练

（1）将 advertisement 服务扩展到两个实例，确认如下：

![image-20200513183042803](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183042803.png)

（2）为 advertisement 服务设置 ROUND_ROBIN 算法的负载均衡：

```bash
kubectl apply -f chapter-files/traffic-management/dr-advertisement-round-robin.yaml -n weather
```

（3）进入 frontend 容器，对 advertisement 服务发起 6 个请求：

```bash
kubectl -n weather exec -it frontend-v1-75d4648dc6-fqx9c bash for i in seq 1 6; do curl http://advertisement.weather:3003/ad --silent -w "Status: %{http_code}\n" -o dev/null; done
```

（4）分别查看两个实例的 Proxy 日志，可以看到他们各自收到了 3 个请求，表示对 advertisement 服务发起的 6 个请求被平均分配到了两个后端实例

```bash
kubectl -n weather logs advertisement-v1-68d74cc5bd-4x62w -c istio-proxy
```

![image-20200513183105099](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183105099.png)

```bash
kubectl -n weather logs advertisement-v1-68d74cc5bd-xr9m6 -c istio-proxy
```

![image-20200513183142173](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183142173.png)

### 1.1.3. 工作原理

查看 advertisement 服务的 DestinationRule 配置：

```bash
kubectl get dr advertisement-dr -oyaml -n weather
```

![image-20200513183200688](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183200688.png)

## 1.2. RANDOM 模式

### 1.2.1. 实验目标

为 advertisement 服务配置 RANDOM 算法，期望对 advertisement 服务的请求被随机分配到后端实例。

### 1.2.2. 实验演练

（1）将 advertisement 服务扩展到两个实例，确认如下：

![image-20200513183316353](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183316353.png)

（2）为 advertisement 服务设置 RANDOM 算法的负载均衡：

```bash
kubectl apply -f chapter-files/traffic-management/dr-advertisement-random.yaml -n weather
```

查看下发的配置：

![image-20200513183217091](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183217091.png)

（3）进入 frontend 容器，对 advertisement 服务发起 6 个请求：

```bash
kubectl -n weather exec -it frontend-v1-75d4648dc6-fqx9c bash for i in seq 1 6; do curl http://advertisement.weather:3003/ad --silent -w "Status: %{http_code}\n" -o dev/null; done
```

（4）分别查看两个实例的 Proxy 日志，可以看到一个实例收到 2 个请求，另一个实例收到 4 个请求，请求分配不再均匀：

```bash
kubectl -n weather logs advertisement-v1-68d74cc5bd-4x62w -c istio-proxy
```

![image-20200513183621592](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183621592.png)

```bash
kubectl -n weather logs advertisement-v1-68d74cc5bd-xr9m6 -c istio-proxy
```

![image-20200513183651675](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183651675.png)

# 2. 会话保持

会话保持是将来自同一客户端的请求始终映射到同一个后端实例中，让请求具有记忆性。会话保持带来的好处是：如果在服务端的缓存中保存着客户端的请求结果，

且同一个客户端始终访问同一个后端实例，就可以一直从缓存中获取数据。Istio 利用一致性哈希算法提供了会话保持功能，也属于负载均衡算法，这种负载均衡只对

HTTP 连接有效。

## 2.1. 实验目标

对 advertisement 服务配置会话保持策略，期望将对 advertisement 服务的所有请求都被转发到同一个后端实例。

## 2.2. 实验演练

（1）将 advertisement 服务扩展到两个实例，确认如下：

![image-20200513183733564](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183733564.png)

（2）为 advertisement 服务设置会话保持模式的负载均衡，根据 Cookie 中的 user 数据得到所使用的哈希值。

```bash
kubectl apply -f chapter-files/traffic-management/dr-advertisement-consistenthash.yaml -n weather
```

查看下发配置：

![image-20200513183759034](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183759034.png)

（3）进入 frontend 容器，对 advertisement 服务发起在 Cookie 中携带 user 信息的 6 个请求：

```bash
kubectl -n weather exec -it frontend-v1-75d4648dc6-fqx9c bash for i in seq 1 6; do curl http://advertisement.weather:3003/ad --cookie “user=tester” --silent -w "Status: %{http_code}\n" -o dev/null; done
```

（4）分别查看两个实例的 Proxy 日志，期望看到一个实例收到这6个请求，说明会话保持策略生效了；实际看到一个实例收到2个请求，另一个实例收到4个请求，反复几次实验，都没有得到期望的结果，实验失败。

```bash
kubectl -n weather logs advertisement-v1-68d74cc5bd-4x62w -c istio-proxy
```

![image-20200513183830007](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183830007.png)

```bash
kubectl -n weather logs advertisement-v1-68d74cc5bd-xr9m6 -c istio-proxy
```

![image-20200513183852955](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183852955.png)

# 3. 故障注入

故障注入是一种软件测试方法，通过在代码中引入故障来发现系统软件中隐藏的 Bug，并且通常与压力测试一起用于验证软件的稳定性。目前，

Istio 故障注入功能支持延迟注入和中断注入。

## 3.1. 延迟注入

延迟属于时序故障，模仿增加的网络延迟或过载的上游服务。故障配置可以设置在特定条件下对请求注入故障，也可以限制发生请求故障的百分比。

### 3.1.1. 实验目标

为 advertisement 服务注入 3 秒的延迟，期望访问 advertisement 服务的返回时间是 3 秒。

### 3.1.2. 实验演练

（1）在正常情况下，进入 frontend 容器访问 advertisement 服务，可以看到返回时间远远少于 3 秒，如下：

![image-20200513183928648](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513183928648.png)

![image-20200513184003492](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184003492.png)

（2）为 advertisement 服务注入 3 秒的延迟调用：

```
kubectl apply -f chapter-files/traffic-management/vs-advertisement-fault-delay.yaml -n weather
```

查看配置：

![image-20200513184032580](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184032580.png)

（3）进入frontend 容器访问 advertisement 服务，查询得到的返回时间是 3 秒，延迟注入成功：

![image-20200513184053176](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184053176.png)

![image-20200513184131730](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184131730.png)

（4）验证完成后删除故障策略

```bash
kubectl delete -f chapter-files/traffic-management/vs-advertisement-fault-delay.yaml -n weather
```

## 3.2. 中断注入

中断注入是模拟上游服务的崩溃失败，通常以 HTTP 地址错误或 TCP 连接失败的形式出现。

### 3.2.1. 实验目标

为 advertisement 服务注入 HTTP 500 错误，期望在访问 advertisement 服务时始终返回 “500” 状态码。

### 3.2.2. 实验演练

（1）为 advertisement 服务的调用注入 HTTP 500 错误：

```bash
kubectl apply -f chapter-files/traffic-management/vs-advertisement-fault-abort.yaml -n weather
```

查看配置：

![image-20200513184210795](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184210795.png)

（2）进入 frontend 容器访问 advertisement 服务，返回 “500” 状态码，说明故障注入成功：

![image-20200513184230835](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184230835.png)

![image-20200513184245290](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184245290.png)

（3）验证完毕后删除故障策略

```bash
kubectl delete -f chapter-files/traffic-management/vs-advertisement-fault-abort.yaml -n weather
```

# 4. 超时

程序在长时间不能正常返回时，需要设置超时控制机制，即过了设置的时间就应该返回错误。如果长期处于等待状态，就会浪费资源，甚至引起级联错误导致整个系统不可用。虽然超时配置可以

通过修改程序的代码完成，但是这样不灵活，可以利用 Istio 设置超时参数达到上述目的。

## 4.1. 实验目标

如果 forecast 服务处理请求的时间超过 1 秒，则请求端收到超时错误。

## 4.2. 实验演练

（1）为 forecast 服务设置 1 秒的超时：

```bash
kubectl apply -f chapter-files/traffic-management/vs-forecast-timeout.yaml -n weather
```

查看配置：

![image-20200513184310027](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184310027.png)

（2）在浏览器查询天气信息，始终可以看到推荐的信息。服务调用关系如下：

frontend v1 → forecast v2 → recommendation v1

为了使 forecast 服务的返回时间多于 1 秒触发超时，给 recommendation 服务注入一段 4 秒的延迟，使 forecast 服务在 1 秒内收不到 recommendation 的响应，不能向 frontend 服务及时返回信息，

从而导致超时报错。为 recommendation 服务注入 4 秒的延迟：

```bash
kubectl apply -f chapter-files/traffic-management/vs-recommendation-fault-delay.yaml -n weather
```

查看配置：

![image-20200513184339704](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184339704.png)

（3）进入 frontend 容器访问 forecast 服务，返回 “504” 超时错误：

![image-20200513184402472](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184402472.png)

（4）验证完毕，删除超时策略

```bash
kubectl delete -f chapter-files/traffic-management/vs-recommendation-fault-delay.yaml -n weather kubectl delete -f chapter-files/traffic-management/vs-forecast-timeout.yaml -n weather
```

# 5. 重试

服务在网络不稳定的环境中经常会返回错误，这是需要增加重试机制，通过多次尝试返回正确结果。虽然也可以将重试逻辑写在业务代码中，但 Istio 可以让开发人员

通过简单配置就可以完成重试功能，不用去考虑这部分的代码实现，增强服务的鲁棒性。

## 5.1. 实验目标

当对 forecast 服务请求失败（返回码为 500）时，请求端自动重试 3 次。

## 5.2. 实验演练

（1）为 recommendation 服务注入故障：

```bash
kubectl apply -f chapter-files/traffic-management/vs-recommendation-fault-abort.yaml -n weather
```

查看配置：

![image-20200513184444501](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184444501.png)

（2）进入 frontend 容器访问一次 forecast 服务，由于 recommendation 被注入错误，导致 forecast 服务也返回 “5xx” 状态码。

![image-20200513184503634](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184503634.png)

（3）查看 forecast 服务 v2 版本的 Proxy 日志，期望看到同一时刻只要 1 次请求记录，实际看到同一时刻有 3 次请求记录，这块比较奇怪

```bash
kubectl logs -f forecast-v2-5668689589-fntwt -n weather -c istio-proxy | grep "GET /weather"
```

![image-20200513184518423](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184518423.png)

（4）对 forecast 服务设置重试机制：

![image-20200513184540140](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184540140.png)

这里的 retries 表示：如果服务在 1 秒内没有得到正确的返回值，就认为这次请求失败，然后重试 3 次，重试条件是返回码为 “5xx”。

（5）进入 frontend 容器再次访问 forecast 服务：

![image-20200513184603159](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184603159.png)

（6）查看 forecast 服务的 Proxy 日志，发现同一时刻有 4 次请求记录（有 3 次是重试的请求）：

```bash
kubectl logs -f forecast-v2-5668689589-fntwt -n weather -c istio-proxy | grep "GET /weather"
```

![image-20200513184617612](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184617612.png)

（7）验证完毕，删除重试策略

```bash
kubectl apply -f install/virtual-service-all.yaml -n weather
```

# 6. HTTP 重定向

HTTP 重定向能够让单个页面、表单或者整个 Web 应用都跳转到新的 URL 下，该操作可以应用于多种场景：网站维护期间的临时跳转，网站架构改变后为了保持

外部链接继续可用的永久重定向，上传文件时的进度页面等。

## 6.1. 实验目标

将对 advertisement 服务的路径 “/ad” 的请求重定向到 “http://advertisement.weather.svc.cluster.local/maintenanced”。

## 6.2. 实验演练

（1）设置重定向规则：

```bash
kubectl apply -f chapter-files/traffic-management/redirect.yaml -n weather
```

查看配置：

![image-20200513184638742](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184638742.png)

HTTP 重定向用来向下游服务发送 “301” 转向响应，并且能够用特定值来替换响应中的认证、主机及 URI 部分。上面的规则会将向 advertisement 服务的 “/ad” 路径

发送的请求重定向到 http://advertisement.weather.svc.cluster.local/maintenanced。

（2）进入 frontend 容器，对 advertisement 服务发起请求，返回 “301” 状态码：

![image-20200513184659956](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184659956.png)

（3）清除规则

```bash
kubectl apply -f install/virtual-service-all.yaml -n weather
```

# 7. HTTP 重写

HTTP 重写用来在 HTTP 请求被转发到目标之前，对请求的内容进行部分改写。

## 7.1. 实验目标

在 访问 advertisement 服务时，期望对路径 “/demo” 的访问能够自动重写成对 advertisement 服务的请求。

## 7.2. 实验演练

（1）设置重定向规则：

```bash
kubectl apply -f chapter-files/traffic-management/rewrite.yaml -n weather
```

查看配置：

![image-20200513184720663](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184720663.png)

在对 advertisement 服务的 API 进行调用之前，Istio 会将 URL 前缀 “/demo” 替换成 "/"。

（2）进入 frontend 容器，对 advertisement 服务发起请求，如果请求路径不带 “/demo”，则返回 “404” 响应码；再次对 advertisement 服务发起请求，请求路径带 “/demo”，返回成功：

![image-20200513184744441](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184744441.png)

（3）清除规则

```bash
kubectl apply -f install/virtual-service-all.yaml -n weather
```

# 8. 熔断

服务端的 Proxy 会记录调用发生错误的次数，然后根据配置决定是否继续提供服务或者立刻返回错误。使用熔断机制可以保护服务后端不会过载。

## 8.1. 实验目标

在对 forecast 服务发起多个并发请求的情况下，为了保护系统整体的可用性，Istio 根据熔断配置会对一部分请求直接返回 “503” 状态码，表示服务处于不可接收请求状态。

另外，在服务被检测到一段时间内发生了多次连续异常后，Istio 会对部分后端实例进行隔离。

## 8.2. 实验演练

（1）部署访问 forecast 服务的客户端 fortio，这个程序可以控制连接数、并发数及 HTTP 请求的延迟，安装文件在 Istio 安装包的 sample 目录中。

```bash
kubectl apply -f samples/httpbin/sample-client/fortio-deploy.yaml -n weather
```

![image-20200513184835859](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184835859.png)

fortio 也被注入了 Proxy，可通过查看 fortio 客户端中 Proxy 的统计日志验证熔断效果

为了更好的演示效果，建议将 forecast 服务的实例扩展到 5 个

![image-20200513184850330](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184850330.png)

（2）为 forecast 服务配置熔断策略

```bash
kubectl apply -f chapter-files/traffic-management/circuit-breaking.yaml -n weather
```

![image-20200513184908474](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184908474.png)

connectionPool 表示如果对 forecast 服务发起超过 3 个 HTTP/1.1 的连接，并且存在 5 个及以上的待处理请求，就会触发熔断机制。

（3）进入 fortio 容器，使用 10 个并发进行 100 次调用触发熔断：

```bash
kubectl exec -it fortio-deploy-7cb865f87f-grnqg -n weather -c fortio /usr/bin/fortio -- load -c 10 -qps 0 -n 100 -loglevel Warning http://forecast.weather:3002/weather?locate=hangzhou
```

![image-20200513184932083](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184932083.png)

上面结果表示有 95% 的请求成功，其余部分则被熔断（“503 Service Unavailable” 表示服务处于不可接收请求状态，由 Proxy 直接返回此状态码）。

为了进一步验证测试结果，在 fortio 客户端的 Proxy 客户端的 Proxy 中查看统计信息

![image-20200513184952457](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513184952457.png)

upstream_rq_pending_overflow 表明有 5 次调用被标记为熔断。

（4）接下来验证异常检测功能：

![image-20200513185008043](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185008043.png)

outlierDetection 表示每 10 秒扫描一次 forecast 服务的后端实例，在连续返回两次网关错误（状态码为502，503 或 504，但不包括 500），实例中的 40% 就会被移出连接池两分钟。 

为 forecast 服务设置超时并对 recommendation 服务注入延迟故障，导致所有访问 forecast 服务的请求都返回 “504” 错误

```bash
kubectl -n weather apply -f chapter-files/traffic-management/vs-forecast-timeout.yaml kubectl -n weather apply -f chapter-files/traffic-management/vs-recommendation-fault-delay.yaml
```

（5）进入 fortio 容器，使用 5 个并发连接进行 20 次调用，触发连续网关故障异常检测：

```bash
kubectl -n weather exec -it fortio-deploy-7cb865f87f-grnqg -c fortio /usr/bin/fortio -- load -c 5 -qps 0 -n 20 -loglevel Warning http://forecast.weather:3002/weather?locate=hangzhou
```

![image-20200513185037765](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185037765.png)

由于没有达到 connectionPool 的限制，不会触发熔断返回 “503”，所有请求都返回 “504 Gateway Timeout”。在 fortio 客户端的 Proxy 中查看异常检测结果：

![image-20200513185129898](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185129898.png)

ejections_active: 2 表示有两个服务实例被移除了负载均衡池。两分钟的移除时间过后，再去查看统计结果，之前被移除的两个实例又被移回了负载均衡池。

（6）清除规则

```bash
kubectl apply -f install/virtual-service-all.yaml -n weather
```

# 9. 限流

限流是一种预防措施，在灾难发生前就对并发访问进行限制。Istio 的速率限制特性可以实现常见的限流功能，即防止来自外部服务的过度调用。衡量指标主要是 QPS，实现方式是计数器方式。Istio 支持 Memquota 适配器和 Redisquota 适配器，

为了方便，实验使用 Memquota 适配器。

## 9.1. 普通方式

### 9.1.1. 实验目标

对目标服务 advertisement 在上线前进行性能测试，找到此服务最大能承受的性能值，在上线时利用这个性能值设置限流规则，使得在请求达到限制的速率时触发限流。Istio 的限流是直接拒绝多出来的请求，对客户端返回

“429：RESOURCE_EXHAUSTED”。

### 9.1.2. 实验演练

（1）验证是否启用了 Istio 策略检查功能：

```bash
kubectl -n istio-system get cm istio -o jsonpath="{@.data.mesh}" | grep disablePolicyChecks
```

![image-20200513185228495](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185228495.png)

disablePolicyChecks: false 表示开启了策略检查。如果没有开启，可以使用 helm upgrade 更新 disablePolicyChecks 参数，开启策略检查功能。

（2）为 advertisement 服务配置速率限制：

```bash
kubectl apply -f chapter-files/traffic-management/ratelimiting.yaml
 
vim chapter-files/traffic-management/ratelimiting.yaml
 
apiVersion: config.istio.io/v1alpha2
kind: handler
metadata:
  name: quotahandler
  namespace: istio-system
spec:
  compiledAdapter: memquota
  params:
    quotas:
    - name: requestcount.instance.istio-system
      maxAmount: 200
      validDuration: 1s
      overrides:
      - dimensions:
          destination: advertisement
        maxAmount: 4
        validDuration: 5s
---
apiVersion: config.istio.io/v1alpha2
kind: instance
metadata:
  name: requestcount
  namespace: istio-system
spec:
  compiledTemplate: quota
  params:
    dimensions:
      source: request.headers["x-forwarded-for"] | "unknown"
      destination: destination.labels["app"] | destination.service.host | "unknown"
      destinationVersion: destination.labels["version"] | "unknown"
---
apiVersion: config.istio.io/v1alpha2
kind: rule
metadata:
  name: quota
  namespace: istio-system
spec:
  actions:
  - handler: quotahandler
    instances:
    - requestcount
---
apiVersion: config.istio.io/v1alpha2
kind: QuotaSpec
metadata:
  name: request-count
  namespace: istio-system
spec:
  rules:
  - quotas:
    - charge: 1
      quota: requestcount
---
apiVersion: config.istio.io/v1alpha2
kind: QuotaSpecBinding
metadata:
  name: request-count
  namespace: istio-system
spec:
  quotaSpecs:
  - name: request-count
    namespace: istio-system
  services:
  - name: advertisement
    namespace: weather
```

从上配置可以看出，Memquota 规定 advertisement 服务在 5 秒内最多能被访问 4 次。

（3）进入 frontend 容器，执行如下命令对 advertisement 服务在 5 秒内发起 5 个请求：可以看到 5 秒限制 4 次请求的速率并未完全匹配

![image-20200513185258588](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185258588.png)

（4）清除规则

```bash
kubectl delete -f chapter-files/traffic-management/ratelimiting.yaml
```

## 9.2. 条件方式

### 9.2.1. 实验目标

Istio 速率限制还可以用于另一种场景：普通用户在使用 advertisement 服务时，只被提供免费的配额，若超过免费配额的请求，则被限制。对于付费的特殊用户会取消速率限制。

### 9.2.2. 实验演练

（1）执行如下命令：

```bash
kubectl apply -f chapter-files/traffic-management/ratelimiting.yaml kubectl apply -f chapter-files/traffic-management/ratelimiting-conditional.yaml
```

查看配置：

![image-20200513185332742](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185332742.png)

上面的规则利用了 Rule 的 match 字段实现了有条件的速率限制：如果在请求的 cookie 信息中带有 user=tester，就不会执行限流策略。

（2）执行如下命令对 advertisement 服务发起多次请求。

结果如下：对 tester 用户没有配额限制，非 tester 用户受到了速率限制。

![image-20200513185402586](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185402586.png)

（3）清除规则：

```bash
kubectl delete -f chapter-files/traffic-management/ratelimiting-conditional.yaml kubectl delete -f chapter-files/traffic-management/ratelimiting.yaml
```

# 10. 服务隔离

Sidecar 资源的配置支持定义 Sidecar 可访问的服务范围，让用户能够更精确控制 Sidecar 行为。

## 10.1. 实验目标

配置 Sidecar 资源使 weather 命名空间下的 httpbin 服务对 default 命名空间下的 sleep 服务不可见，即 sleep.default 只能访问 httpbin.default，不能访问 httpbin.weather。

## 10.2. 实验演练

（1）在 default 命名空间下部署 Istio 安装包中的 sleep 和 httpbin 两个服务：

```bash
kubectl label ns default istio-injection=enabled kubectl apply -f samples/sleep/sleep.yaml kubectl apply -f samples/httpbin/httpbin.yaml
```

在 weather 命名空间下部署 Istio 安装包中的 httpbin 服务：

```bash
kubectl apply -f samples/httpbin/httpbin.yaml -n weather
```

（2）进入 sleep.defautl 的 Proxy 查看 clusters，可以看到 httpbin.default 和 httpbin.weather 的信息：

![image-20200513185446853](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185446853.png)

从 sleep.default 容器中分别访问 httpbin.default 和 httpbin.weather，请求均成功：

![image-20200513185504749](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185504749.png)

（3）为命名空间 default 配置 Sidecar 资源对象：

```bash
kubectl apply -f chapter-files/traffic-management/sidecar-demo.yaml
```

查看配置：

![image-20200513185532609](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185532609.png)

其规则表示在 default 命名空间下 sleep 工作负载对外只能访问 default 和 istio-system 两个命名空间下的服务。

（4）进入 sleep.default 的 Proxy 查看 clusters，只能看到 httpbin.default 的信息，http.weather 信息不见了：

![image-20200513185547532](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185547532.png)

再次在 sleep.default 的容器中访问不同命名空间下的两个服务，httpbin.weather 期望返回 “404”，实际返回 "200"，httpbin.default 仍然能正常响应：

![image-20200513185600115](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185600115.png)

# 11. 影子测试

查找新代码错误的最佳方法是在实际环境中进行测试。影子测试可以将生产流量复制到目标服务中进行测试，在处理中产生的任何错误都不会对真个系统的性能和可靠性造成影响。

## 11.1. 实验目标

测试 forecast 服务的 v2 版本在真实用户访问下的表现，但同时不想影响到终端用户，这时就需要复制一份 forecast 服务的 v1 版本的流量给 forecast 服务的 v2 版本，观察 v2 版本在复制的数据流下的行为

和影响指标。

## 11.2. 实验演练

（1）部署 forecast 服务的 v1 和 v2 版本，设置策略使访问 forecast 服务的流量都被路由到 forecast 服务的 v1 版本。

```bash
kubectl apply -f install/virtual-service-v1.yaml -n weather
```

在浏览器查询天气信息，看不到推荐信息。这时查询 forecast 服务的 v2 实例的 Proxy 日志，或者通过可视化工具，可以确定服务的 v2 版本的实例上没有任何流量。

![image-20200513185633381](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185633381.png)

（2）执行如下命令设置影子策略，复制 v1 版本流量给 v2 版本：

```bash
kubectl apply -f chapter-files/traffic-management/vs-forecast-mirroring.yaml -n weather
```

在浏览器中查询天气信息，我们没有看到推荐信息，说明 forecast 服务的 v2 版本没有将结果返回给 frontend 服务，那么 forecast 服务的 v2 版本有没有收到流量？分别查看 forecast 服务的 v1 版本

和 v2 版本 Proxy 日志，可以看到两个实例同时收到了请求，forecast 服务的 v1 版本流量被 Proxy 复制了一份发给 v2 版本的实例：

![image-20200513185650362](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185650362.png)

![image-20200513185707385](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185707385.png)

通过可视化工具可以看到，虽然 frontend 服务没有调用 forecast 服务的 v2 版本，但这时 recommendation 服务的实例有流量出现，说明在 forecast 服务的 v2 版本上存在隐藏的流量：

![image-20200513185725590](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185725590.png)

## 11.3. 工作原理

查看配置：

![image-20200513185741597](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200513185741597.png)

上面配置的策略将全部流量都发送到 forecast 服务的 v1 版本，其中的 mirror 字段指定将流量复制到 forecast 服务的 v2 版本。当流量被复制时，会在请求的 HOST 或 Authority

头中添加 -shadow 后缀（如 forecast-shadow），并将请求发送到 forecast 服务的 v2 版本以示它是影子流量。这些被复制的请求引发的响应会被丢弃，不会影响终端客户。