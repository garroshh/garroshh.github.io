---
title: "流量监控"
date: 2020-05-11T19:01:49+08:00
draft: false

tags: ["Istio", "实验"]
categories: ["Istio"]
---

Istio 的 Proxy 通过拦截系统中所有网络的通信，来提供可用于获得整个应用的可观察性的指标和数据。比如：若一个服务响应过慢是由

CPU 占用率过高导致的，则可以采用弹性伸缩来解决问题；若一个服务响应过慢是由于访问量突然增大引起的，则可以采取熔断限流等措施。

# 1. 预先准备：安装插件

在使用 Istio 的流量功能前，需要在集群中安装 Jaeger、Prometheus、Grafana 和 Kiali 等插件。如果这些插件在部署时未启用，则可以使用

helm upgrade 命令进行启用。

- Grafana：–set grafana.enabled=true
- Kiali：–set kiali.enabled=true
- Prometheus：–set prometheus.enabled=true
- Tracing：–set tracing.enabled=true

在登录 Kiali 时需要输入用户名和密码，执行以下命令创建 Kiali 的 Secret：

```bash
kubectl apply -f chapter-files/telemetry/kiali-secret.yaml
```

kiali-secret.yaml 保存了经过 Base64 编码的用户和密码信息，初始的用户名是 admin，密码也是 admin。可以在 Secret 中按需修改这部分信息，

在创建 Secret 后有些 Kiali 版本需要重启才能生效。

所有插件都安装成功后，为了在集群外的浏览器中打开界面，需配置每个插件的对外访问方式，如下命令使用 Gateway 设置 HTTP 访问各插件：

```bash
kubectl apply -f chapter-files/telemetry/access-addons.yaml
```

Gateway 资源创建完成后，在浏览器输入对应插件的地址进行访问：

- Kiali：http://<IP>:15029/kiali
- Prometheus：http://<IP>:15030/
- Grafana：http://<IP>:15031/
- Tracing：http://<IP>:15032/

# 2. 调用链跟踪

调用链跟踪是一种用于分析和监控微服务应用的方法，OpenTracing 是分布式跟踪的 API 规范，提供了统一的接口，方便开发者在自己的服务中集成

一种或多种分布式追踪的实现。Istio 使用 Jaeger 作为调用链的引擎。

一次调用链跟踪（Trace）由若干个 Span 组成，Span 是请求数据的最小单位，包括这次跟踪的开始时间、结束时间、操作名称及一组标签和日志。尽管

Proxy 可以自动生成 Span，但是应用程序需要传播响应的 HTTP Header，这样这些 Span 才能被正确关联到一个跟踪。因此，需要应用程序手机传入请求

中的以下 HTTP Header 并将其传播出去。

- x-request-id
- x-b3-traceid
- x-b3-spanid
- x-b3-parentspanid
- x-b3-sampled
- x-b3-flags
- x-ot-span-context

访问 Jaeger 页面：[http://10.12.1.100:30655/](http://10.12.1.100:30655/jaeger/search)

![image-20200511190507400](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511190507400.png)

在浏览器中访问前台页面查询天气，在这个过程中会产生调用链信息。从界面左边面板的 Service 下拉列表中选择 frontend.weather，并单击左下角

"Find Traces" 按钮检索调用链，右侧会显示调用链记录的列表：

![image-20200511190534409](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511190534409.png)

调用链数据的频繁采集会对系统造成严重的性能损失，Istio 为了提高系统性能，设置默认采样率为 1%。如果遇到调用链不能正常获取的情况，则需要调整

跟踪取样率。Istio 的跟踪取样率被设置为 istio-pilot 的环境变量 PILOT_TRACE_SAMPLING，取值范围为 1.0 ~ 100.0：

```bash
kubectl -n istio-system edit deploy istio-pilot
```

![image-20200511190556547](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511190556547.png)

单击某一个跟踪记录，可以查看其包含的所有 Span 和每个 Span 的消耗时间。如下的跟踪信息有 4 个 Span，涉及 3 个服务，一共耗时 7.21 毫秒。

![image-20200511190623214](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511190623214.png)

在跟踪（Trace）的详情页可以单击某个 Span 来查看其详细信息，包括被调用的 URL、HTTP 方法、响应状态和其他 Header 信息

![image-20200511190650337](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511190650337.png)

此外，Jaeger 还提供了 Compare 功能（用来对比不同 Trace 信息）和 Dependencies 视图（展现各个服务如何相互调用）。

![image-20200511190711960](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511190711960.png)

# 3. 指标监控

Metrics 是服务的监控指标数据，指标数据通常分为 4 类：Counter、Gauge、Histogram 和 Summary。Istio 内置了几种常见的度量标准类型，

也可以创建自定义指标。

### Prometheus

Istio 默认启用了预置的 Prometheus 组件，配置文件被定义在 istio-system 命名空间下的名称为 Prometheus 的 ConfigMap 中，并被挂载到

Prometheus 的 Pod 内。Prometheus 容器内的配置文件 "/etc/prometheus/prometheus.yaml" 如下：

```yaml
kubectl get cm prometheus -n istio-system -oyaml
 
apiVersion: v1
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
    scrape_configs:
 
    - job_name: 'istio-mesh'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - istio-system
 
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: istio-telemetry;prometheus
 
    # Scrape config for envoy stats
    - job_name: 'envoy-stats'
      metrics_path: /stats/prometheus
      kubernetes_sd_configs:
      - role: pod
 
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_container_port_name]
        action: keep
        regex: '.*-envoy-prom'
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:15090
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: pod_name
 
    - job_name: 'istio-policy'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - istio-system
 
 
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: istio-policy;http-monitoring
 
    - job_name: 'istio-telemetry'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - istio-system
 
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: istio-telemetry;http-monitoring
 
    - job_name: 'pilot'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - istio-system
 
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: istio-pilot;http-monitoring
 
    - job_name: 'galley'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - istio-system
 
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: istio-galley;http-monitoring
 
    - job_name: 'citadel'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - istio-system
 
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: istio-citadel;http-monitoring
 
    # scrape config for API servers
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - default
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: kubernetes;https
 
    # scrape config for nodes (kubelet)
    - job_name: 'kubernetes-nodes'
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics
 
    # Scrape config for Kubelet cAdvisor.
    #
    # This is required for Kubernetes 1.7.3 and later, where cAdvisor metrics
    # (those whose names begin with 'container_') have been removed from the
    # Kubelet metrics endpoint.  This job scrapes the cAdvisor endpoint to
    # retrieve those metrics.
    #
    # In Kubernetes 1.7.0-1.7.2, these metrics are only exposed on the cAdvisor
    # HTTP endpoint; use "replacement: /api/v1/nodes/${1}:4194/proxy/metrics"
    # in that case (and ensure cAdvisor's HTTP server hasn't been disabled with
    # the --cadvisor-port=0 Kubelet flag).
    #
    # This job is not necessary and should be removed in Kubernetes 1.6 and
    # earlier versions, or it will cause the metrics to be scraped twice.
    - job_name: 'kubernetes-cadvisor'
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
 
    # scrape config for service endpoints.
    - job_name: 'kubernetes-service-endpoints'
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
        action: replace
        target_label: __scheme__
        regex: (https?)
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: kubernetes_name
 
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:  # If first two labels are present, pod should be scraped  by the istio-secure job.
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      # Keep target if there's no sidecar or if prometheus.io/scheme is explicitly set to "http"
      - source_labels: [__meta_kubernetes_pod_annotation_sidecar_istio_io_status, __meta_kubernetes_pod_annotation_prometheus_io_scheme]
        action: keep
        regex: ((;.*)|(.*;http))
      - source_labels: [__meta_kubernetes_pod_annotation_istio_mtls]
        action: drop
        regex: (true)
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: pod_name
 
    - job_name: 'kubernetes-pods-istio-secure'
      scheme: https
      tls_config:
        ca_file: /etc/istio-certs/root-cert.pem
        cert_file: /etc/istio-certs/cert-chain.pem
        key_file: /etc/istio-certs/key.pem
        insecure_skip_verify: true  # prometheus does not support secure naming.
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      # sidecar status annotation is added by sidecar injector and
      # istio_workload_mtls_ability can be specifically placed on a pod to indicate its ability to receive mtls traffic.
      - source_labels: [__meta_kubernetes_pod_annotation_sidecar_istio_io_status, __meta_kubernetes_pod_annotation_istio_mtls]
        action: keep
        regex: (([^;]+);([^;]*))|(([^;]*);(true))
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
        action: drop
        regex: (http)
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__]  # Only keep address that is host:port
        action: keep    # otherwise an extra target with ':443' is added for https scheme
        regex: ([^:]+):(\d+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: pod_name
kind: ConfigMap
metadata:
  creationTimestamp: "2020-02-17T15:09:41Z"
  labels:
    app: prometheus
    chart: prometheus
    heritage: Helm
    release: istio
  name: prometheus
  namespace: istio-system
  resourceVersion: "1885"
  selfLink: /api/v1/namespaces/istio-system/configmaps/prometheus
  uid: 69739c5d-8cd8-44fd-ae12-a08bf80b3600
```

以上配置中定义了 Prometheus 需要抓取目标数据的参数，例如监控集群中的哪些 Pod，获取 Metrics 的接口路径等。

访问 Prometheus：http://10.12.1.100:31957/

![image-20200511190742237](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511190742237.png)

在网页顶部的 Expression 输入框中输入 “istio”，Prometheus 会自动补齐并显示从 Envoy 收集的所有相关指标。选择或输入 “istio_request_total”，

然后单击 Execute 按钮，检索得到 Istio 请求总数的 Metrics。

![image-20200511190804761](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511190804761.png)

如果没有数据返回，则需要访问前台页面产生 Metrics，并重新检索指标数据。Prometheus 也支持组合查询表达式，例如想查询过去 5 分钟对

advertisement 服务的请求成功率，则输入如下表达式：

```bash
sum(rate(istio_requests_total{
  reporter="destination",
  destination_service_namespace="weather",
  destination_service_name="advertisement",
  response_code!~"5.x"
}[5m]
))/sum(rate(istio_requests_total{
  reporter="destination",
  destination_service_namespace="weather",
  destination_service_name="advertisement",
  response_code!~"5.x"
}[5m]
)) * 100
```

![image-20200511190827440](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511190827440.png)

如果 Istio 内置的 Metrics 不能满足需求，则用户还可以创建自定义的 Metrics，例如需要查询请求的 Method、Path 和 Useragent 等属性，执行如下命令：

```bash
kubectl apply -f chapter-files/telemetry/customer-request-count.yaml
```

文件内容如下：

```yaml
apiVersion: config.istio.io/v1alpha2
kind: instance
metadata:
  name: customerrequestcount
  namespace: istio-system
spec:
  compiledTemplate: metric
  params:
    value: "1"
    dimensions:
      method: request.method | "unknown"
      path: request.path | "unknown"
      useragent: request.useragent | "unknown"
      destination: destination.service.name | "unknown"
      code: response.code | 200
    monitored_resource_type: '"UNSPECIFIED"'
---
apiVersion: "config.istio.io/v1alpha2"
kind: handler
metadata:
  name: prometheus
  namespace: istio-system
spec:
  compiledAdapter: prometheus
  params:
    metrics:
    - name: customer_request_count
      instance_name: customerrequestcount.instance.istio-system
      kind: COUNTER
      label_names:
      - method
      - path
      - useragent
      - destination
      - code
---
apiVersion: "config.istio.io/v1alpha2"
kind: rule
metadata:
  name: customerprom
  namespace: istio-system
spec:
  actions:
  - handler: prometheus
    instances:
    - customerrequestcount
```

从浏览器前台页面产生流量，在 Prometheus 界面输入 “istio_customer_request_count”，执行如下：

![image-20200511190856956](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511190856956.png)

# 4. Grafana

Istio 安装包携带了预置的 Grafana 组件，但默认不安装。需启用 Grafana 并配置对外访问方式。

访问 Grafana：http://10.12.1.100:30826/，如下图，可以看到 Istio 定制的 Grafana 集成了包括网络、服务、工作负载和 Istio核心组件

在内的多个 Dashboard。

![image-20200511190921564](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511190921564.png)

### Istio Mesh Dashboard

提供了网格的全局摘要视图，在多次访问应用产生流量后，可以在仪表盘实时看到全局的数据请求量、成功率，以及服务和工作负载

的列表等信息。

![image-20200511190940038](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511190940038.png)

### Istio Service Dashboard

提供了每个服务的 HTTP、gRPC 和 TCP 的请求和响应的度量指标，以及有关此服务的客户端和服务端工作负载的指标。

![image-20200511191000766](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511191000766.png)

### Istio Workload Dashboard

提供了每个工作负载请求流量的动态数据，以及入站和出站的相关指标。

![image-20200511191034525](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511191034525.png)

### Istio Performance Dashboard

用来监控 istio-proxy、istio-telemetry、istio-policy 和 istio-ingressgateway 的 vCPU、内存和每秒传输字节数等关键指标，

用来测量和评估 Istio 的整体性能表现。

![image-20200511191056128](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511191056128.png)

### 自定义 Dashboard

Istio 默认集成的仪表盘缺少对 Kubernetes Pod 的资源使用情况的展示，用户需要创建自定义的仪表盘来监控 Pod 的相关指标。导入

chapter-files/telemetry/Istio-USE-dashboard.json。

![image-20200511191119803](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511191119803.png)

![image-20200511191159590](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511191159590.png)

可以看到，这个 Dashboard 显示了指定命名空间下所有 Pod 的 CPU、内存和网络 I/O 的使用情况。也可以在 Grafana 官网查找其他开发

人员或组织公开发布的配置文件进行使用。如 "https://grafana.com/grafana/dashboards/1471" 展示了指定命名空间下容器的关键 Metrics:

request rate、error rate、response times、pod count、cpu 和 memory usage。

![image-20200511191230600](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511191230600.png)

# 5. 服务网格监控

Istio 默认不安装 Kiali 组件，需启用 Kiali 并配置对外访问方式。

Kiali：http://10.12.1.100:32143/，输入用户名 admin 和密码 admin。

Kiali 总览视图展示了集群中所有命名空间的全局视图，以及各个命名空间下应用的数量、健康状态和其他功能视图的链接图标。

![image-20200511191253964](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511191253964.png)

"Graph" 菜单项可以查看服务拓扑关系，深入了解服务间如何通讯。可从中获取实时的动态流量数据，包括 HTTP/TCP 的每秒请求数、流量比例、

成功率及不同返回码的占比。

![image-20200511191317682](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511191317682.png)

Kiali 中，应用指具有相同标签的服务和工作负载的集合，是一个虚拟概念。如下为应用详情页，可以看到与应用关联的服务和工作负载、健康状况、

入站和出站流量的请求和响应指标等信息。

![image-20200511191340355](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511191340355.png)

工作负载详情页包含了负载的标签、创建时间、健康状态、关联的 Pod 信息、Service 信息、Istio 资源对象 和 Metrics 等。

![image-20200511191402208](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511191402208.png)

服务详情页展示了服务的标签、端口信息、工作负载、健康状态、Istio 资源对象 和 Metrics等。

用户通过上面的信息可以检查 Pod 和 服务是否满足 Istio 规范，如 Service 是否定义了包含协议的端口名称、

Deployment 是否带有正确的 app 和 version 标签等。

![image-20200511191427619](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511191427619.png)

Istio Config 显示了网格中所有的 Istio 资源和规则，用户可以对单个配置进行查看、修改、删除操作。同时，Kiali 会对网格内的

Istio 规则进行在线的语法校验。如果出现网格范围内的配置冲突，Kiali 就会按照严重程度（Warning 或 Error）高亮显示这些冲突

提示用户。如 VituralService 绑定的 Gateway 不存在；Subset 没有定义；同一个主机存在定义了不同 Subset 的多个 DestinationRule 等。

![image-20200511191451819](https://cdn.jsdelivr.net/gh/garroshh/figurebed/img/image-20200511191451819.png)